{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a992d7ab",
   "metadata": {},
   "source": [
    "# Edge Prediction\n",
    "Run this notebook to train a logistic regression model to predict edges. You must first run the `construct_features.ipynb` notebook to create the edge features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51e43cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Whether to generate predictions for intermediate and final test sets\n",
    "intermediate = True\n",
    "final = True\n",
    "\n",
    "# Number of communities for the CHIP model\n",
    "n_communities_A = 3\n",
    "n_communities_B = 110\n",
    "\n",
    "# Data paths\n",
    "datasetA_path = '.'\n",
    "datasetB_path = '.'\n",
    "featureA_path = '.'\n",
    "featureB_path = '.'\n",
    "predictionA_path = '.'\n",
    "predictionB_path = '.'\n",
    "\n",
    "dataA_init_path = os.path.join(datasetA_path, 'input_A_initial.csv')\n",
    "dataB_init_path = os.path.join(datasetB_path, 'input_B_initial.csv')\n",
    "\n",
    "featureA_CHIP_init_path = os.path.join(featureA_path, f'featureA_CHIP_K_{n_communities_A}_initial.csv')\n",
    "featureA_CHIP_inter_path = os.path.join(featureA_path, f'featureA_CHIP_K_{n_communities_A}_intermediate.csv')\n",
    "featureA_CHIP_final_path = os.path.join(featureA_path, f'featureA_CHIP_K_{n_communities_A}_final.csv')\n",
    "featureA_edge_init_path = os.path.join(featureA_path, f'featureA_edge_initial.csv')\n",
    "featureA_edge_inter_path = os.path.join(featureA_path, f'featureA_edge_intermediate.csv')\n",
    "featureA_edge_final_path = os.path.join(featureA_path, f'featureA_edge_final.csv')\n",
    "featureB_CHIP_init_path = os.path.join(featureB_path, f'featureB_CHIP_K_{n_communities_B}_initial.csv')\n",
    "featureB_CHIP_inter_path = os.path.join(featureB_path, f'featureB_CHIP_K_{n_communities_B}_intermediate.csv')\n",
    "featureB_CHIP_final_path = os.path.join(featureB_path, f'featureB_CHIP_K_{n_communities_B}_final.csv')\n",
    "\n",
    "predictionA_inter_path = os.path.join(predictionA_path, 'output_A_intermediate.csv')\n",
    "predictionA_final_path = os.path.join(predictionA_path, 'output_A.csv')\n",
    "predictionB_inter_path = os.path.join(predictionB_path, 'output_B_intermediate.csv')\n",
    "predictionB_final_path = os.path.join(predictionB_path, 'output_B.csv')\n",
    "\n",
    "# Make printed arrays easier to view\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bd23b2",
   "metadata": {},
   "source": [
    "# Dataset A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5927053",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93f2ae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and standardize\n",
    "dataA_init = np.loadtxt(dataA_init_path, delimiter=',')\n",
    "labelsA_init = dataA_init[:, -1]\n",
    "featureA_CHIP_init = np.loadtxt(featureA_CHIP_init_path, delimiter=',')\n",
    "featureA_edge_init = np.loadtxt(featureA_edge_init_path, delimiter=',')\n",
    "\n",
    "# Assemble feature matrix\n",
    "featureA_init = np.hstack((featureA_edge_init, featureA_CHIP_init[:, np.newaxis]))\n",
    "\n",
    "scalerA = StandardScaler()\n",
    "featureA_init = scalerA.fit_transform(featureA_init)\n",
    "\n",
    "if intermediate:\n",
    "    featureA_CHIP_inter = np.loadtxt(featureA_CHIP_inter_path, delimiter=',')\n",
    "    featureA_edge_inter = np.loadtxt(featureA_edge_inter_path, delimiter=',')\n",
    "    # Assemble feature matrix\n",
    "    featureA_inter = np.hstack((featureA_edge_inter, featureA_CHIP_inter[:, np.newaxis]))\n",
    "    featureA_inter = scalerA.transform(featureA_inter)\n",
    "\n",
    "if final:\n",
    "    featureA_CHIP_final = np.loadtxt(featureA_CHIP_final_path, delimiter=',')\n",
    "    featureA_edge_final = np.loadtxt(featureA_edge_final_path, delimiter=',')\n",
    "    # Assemble feature matrix\n",
    "    featureA_final = np.hstack((featureA_edge_final, featureA_CHIP_final[:, np.newaxis]))\n",
    "    featureA_final = scalerA.transform(featureA_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac2b3aa",
   "metadata": {},
   "source": [
    "## Train logistic regression and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "798c16a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression on initial data\n",
    "lr_args = {'penalty': 'l2', 'C': 0.01, 'solver': 'lbfgs'}\n",
    "lrA = LogisticRegression(**lr_args)\n",
    "lrA.fit(featureA_init, labelsA_init)\n",
    "\n",
    "if intermediate:\n",
    "    predictionA_inter = lrA.predict_proba(featureA_inter)[:, -1]\n",
    "    np.savetxt(predictionA_inter_path, predictionA_inter, fmt='%.16g')\n",
    "\n",
    "if final:\n",
    "    predictionA_final = lrA.predict_proba(featureA_final)[:, -1]\n",
    "    np.savetxt(predictionA_final_path, predictionA_final, fmt='%.16g')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1d0da8",
   "metadata": {},
   "source": [
    "# Dataset B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937e9b57",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78311855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and standardize\n",
    "dataB_init = np.loadtxt(dataB_init_path, delimiter=',')\n",
    "labelsB_init = dataB_init[:, -1]\n",
    "featureB_init = np.loadtxt(featureB_CHIP_init_path, delimiter=',')\n",
    "\n",
    "# Change from 1-D to 2-D array since there is only a single feature\n",
    "featureB_init = featureB_init[:, np.newaxis]\n",
    "\n",
    "scalerB = StandardScaler()\n",
    "featureB_init = scalerB.fit_transform(featureB_init)\n",
    "\n",
    "if intermediate:\n",
    "    featureB_inter = np.loadtxt(featureB_CHIP_inter_path, delimiter=',')\n",
    "    # Change from 1-D to 2-D array since there is only a single feature\n",
    "    featureB_inter = featureB_inter[:, np.newaxis]\n",
    "    featureB_inter = scalerB.transform(featureB_inter)\n",
    "\n",
    "if final:\n",
    "    featureB_final = np.loadtxt(featureB_CHIP_final_path, delimiter=',')\n",
    "    # Change from 1-D to 2-D array since there is only a single feature\n",
    "    featureB_final = featureB_final[:, np.newaxis]\n",
    "    featureB_final = scalerB.transform(featureB_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec8a174",
   "metadata": {},
   "source": [
    "## Train logistic regression and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "968c1361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression on initial data\n",
    "lr_args = {'penalty': 'l2', 'C': 0.001, 'solver': 'lbfgs'}\n",
    "lrB = LogisticRegression(**lr_args)\n",
    "lrB.fit(featureB_init, labelsB_init)\n",
    "\n",
    "if intermediate:\n",
    "    predictionB_inter = lrB.predict_proba(featureB_inter)[:, -1]\n",
    "    np.savetxt(predictionB_inter_path, predictionB_inter, fmt='%.16g')\n",
    "\n",
    "if final:\n",
    "    predictionB_final = lrB.predict_proba(featureB_final)[:, -1]\n",
    "    np.savetxt(predictionB_final_path, predictionB_final, fmt='%.16g')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
